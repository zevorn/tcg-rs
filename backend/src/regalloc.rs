use crate::code_buffer::CodeBuffer;
use crate::constraint::OpConstraint;
use crate::HostCodeGen;
use tcg_core::label::RelocKind;
use tcg_core::temp::TempKind;
use tcg_core::types::{RegSet, TempVal};
use tcg_core::{Context, OpFlags, Opcode, TempIdx, OPCODE_DEFS};

/// Register allocator state.
struct RegAllocState {
    reg_to_temp: [Option<TempIdx>; 16],
    free_regs: RegSet,
    allocatable: RegSet,
}

impl RegAllocState {
    fn new(allocatable: RegSet) -> Self {
        Self {
            reg_to_temp: [None; 16],
            free_regs: allocatable,
            allocatable,
        }
    }

    fn free_reg(&mut self, reg: u8) {
        self.reg_to_temp[reg as usize] = None;
        if self.allocatable.contains(reg) {
            self.free_regs = self.free_regs.set(reg);
        }
    }

    fn assign(&mut self, reg: u8, tidx: TempIdx) {
        self.reg_to_temp[reg as usize] = Some(tidx);
        self.free_regs = self.free_regs.clear(reg);
    }
}

// -- Helper functions --

/// Evict the current occupant of `reg`. Globals are synced to
/// memory; locals are moved to a free register.
fn evict_reg(
    ctx: &mut Context,
    state: &mut RegAllocState,
    backend: &impl HostCodeGen,
    buf: &mut CodeBuffer,
    reg: u8,
) {
    let Some(tidx) = state.reg_to_temp[reg as usize] else {
        return;
    };
    let temp = ctx.temp(tidx);
    if temp.is_global_or_fixed() {
        // Sync to memory and mark Mem
        temp_sync(ctx, backend, buf, tidx);
        let t = ctx.temp_mut(tidx);
        t.val_type = TempVal::Mem;
        t.reg = None;
        t.mem_coherent = true;
        state.free_reg(reg);
    } else {
        // Move local to another free register
        let ty = temp.ty;
        let free = state.free_regs.subtract(RegSet::from_raw(1u64 << reg));
        let dst = free.first().expect("no free register for eviction");
        backend.tcg_out_mov(buf, ty, dst, reg);
        state.free_reg(reg);
        state.assign(dst, tidx);
        let t = ctx.temp_mut(tidx);
        t.reg = Some(dst);
    }
}

/// Allocate a register from `required & ~forbidden`, preferring
/// `preferred`. Evicts an occupant if necessary. If all required
/// registers are forbidden (e.g. fixed constraint conflicts with
/// a prior input), evict the forbidden occupant first.
fn reg_alloc(
    ctx: &mut Context,
    state: &mut RegAllocState,
    backend: &impl HostCodeGen,
    buf: &mut CodeBuffer,
    required: RegSet,
    forbidden: RegSet,
    preferred: RegSet,
) -> u8 {
    let candidates = required.intersect(state.allocatable).subtract(forbidden);
    // Try preferred & free first
    let pref_free = candidates.intersect(state.free_regs).intersect(preferred);
    if let Some(r) = pref_free.first() {
        return r;
    }
    // Try any free
    let any_free = candidates.intersect(state.free_regs);
    if let Some(r) = any_free.first() {
        return r;
    }
    // Try evicting a non-forbidden occupant
    if let Some(r) = candidates.first() {
        evict_reg(ctx, state, backend, buf, r);
        return r;
    }
    // All required regs are forbidden — must evict a forbidden
    // occupant (e.g. fixed RCX constraint vs prior input in RCX).
    let forced = required.intersect(state.allocatable);
    let r = forced
        .first()
        .expect("no candidate register for allocation");
    evict_reg(ctx, state, backend, buf, r);
    r
}

/// Load a temp into a register satisfying the constraint.
/// Returns the allocated host register.
#[allow(clippy::too_many_arguments)]
fn temp_load_to(
    ctx: &mut Context,
    state: &mut RegAllocState,
    backend: &impl HostCodeGen,
    buf: &mut CodeBuffer,
    tidx: TempIdx,
    required: RegSet,
    forbidden: RegSet,
    preferred: RegSet,
) -> u8 {
    let temp = ctx.temp(tidx);
    match temp.val_type {
        TempVal::Reg => {
            let cur = temp.reg.unwrap();
            if required.contains(cur) && !forbidden.contains(cur) {
                return cur;
            }
            // Current reg doesn't satisfy — move
            let ty = temp.ty;
            let dst = reg_alloc(
                ctx, state, backend, buf, required, forbidden, preferred,
            );
            backend.tcg_out_mov(buf, ty, dst, cur);
            state.free_reg(cur);
            state.assign(dst, tidx);
            let t = ctx.temp_mut(tidx);
            t.reg = Some(dst);
            dst
        }
        TempVal::Const => {
            let val = temp.val;
            let ty = temp.ty;
            let reg = reg_alloc(
                ctx, state, backend, buf, required, forbidden, preferred,
            );
            state.assign(reg, tidx);
            backend.tcg_out_movi(buf, ty, reg, val);
            let t = ctx.temp_mut(tidx);
            t.val_type = TempVal::Reg;
            t.reg = Some(reg);
            reg
        }
        TempVal::Mem => {
            let ty = temp.ty;
            let mem_base = temp.mem_base;
            let mem_offset = temp.mem_offset;
            let reg = reg_alloc(
                ctx, state, backend, buf, required, forbidden, preferred,
            );
            state.assign(reg, tidx);
            if let Some(base_idx) = mem_base {
                let base_reg = ctx.temp(base_idx).reg.unwrap();
                backend.tcg_out_ld(buf, ty, reg, base_reg, mem_offset);
            }
            let t = ctx.temp_mut(tidx);
            t.val_type = TempVal::Reg;
            t.reg = Some(reg);
            t.mem_coherent = true;
            reg
        }
        TempVal::Dead => {
            panic!("temp_load_to on dead temp {tidx:?}");
        }
    }
}

/// Sync a temp back to memory (for globals).
fn temp_sync(
    ctx: &Context,
    backend: &impl HostCodeGen,
    buf: &mut CodeBuffer,
    tidx: TempIdx,
) {
    let temp = ctx.temp(tidx);
    if temp.mem_coherent {
        return;
    }
    if let (Some(reg), Some(base_idx)) = (temp.reg, temp.mem_base) {
        let base_reg = ctx.temp(base_idx).reg.unwrap();
        backend.tcg_out_st(buf, temp.ty, reg, base_reg, temp.mem_offset);
    }
}

/// Sync all live globals back to memory.
fn sync_globals(
    ctx: &mut Context,
    backend: &impl HostCodeGen,
    buf: &mut CodeBuffer,
) {
    let nb_globals = ctx.nb_globals() as usize;
    for i in 0..nb_globals {
        let tidx = TempIdx(i as u32);
        let temp = ctx.temp(tidx);
        if temp.val_type == TempVal::Reg && !temp.mem_coherent {
            temp_sync(ctx, backend, buf, tidx);
            ctx.temp_mut(tidx).mem_coherent = true;
        }
    }
}

/// Free a temp's register if it's dead after this op.
fn temp_dead(ctx: &mut Context, state: &mut RegAllocState, tidx: TempIdx) {
    let temp = ctx.temp(tidx);
    if temp.is_global_or_fixed() {
        return;
    }
    if let Some(reg) = temp.reg {
        state.free_reg(reg);
    }
    let t = ctx.temp_mut(tidx);
    t.val_type = TempVal::Dead;
    t.reg = None;
}

/// Generic constraint-driven register allocation for one op.
///
/// Mirrors QEMU's `tcg_reg_alloc_op()`.
#[allow(clippy::needless_range_loop)]
fn regalloc_op(
    ctx: &mut Context,
    state: &mut RegAllocState,
    backend: &impl HostCodeGen,
    buf: &mut CodeBuffer,
    op: &tcg_core::Op,
    ct: &OpConstraint,
) {
    let def = &OPCODE_DEFS[op.opc as usize];
    let nb_oargs = def.nb_oargs as usize;
    let nb_iargs = def.nb_iargs as usize;
    let nb_cargs = def.nb_cargs as usize;
    let life = op.life;

    let mut i_regs = [0u8; 10];
    let mut i_allocated = RegSet::EMPTY;
    // Track which aliased inputs can be reused for output
    let mut i_reusable = [false; 10];

    // 1. Process inputs
    for i in 0..nb_iargs {
        let arg_ct = &ct.args[nb_oargs + i];
        let tidx = op.args[nb_oargs + i];
        let required = arg_ct.regs;
        let is_dead = life.is_dead((nb_oargs + i) as u32);
        let temp = ctx.temp(tidx);
        let is_readonly = temp.is_global_or_fixed() || temp.is_const();

        if arg_ct.ialias && is_dead && !is_readonly {
            // Can reuse this input's register for the
            // aliased output.
            let preferred = op.output_pref[arg_ct.alias_index as usize];
            let reg = temp_load_to(
                ctx,
                state,
                backend,
                buf,
                tidx,
                required,
                i_allocated,
                preferred,
            );
            i_regs[i] = reg;
            i_allocated = i_allocated.set(reg);
            i_reusable[i] = true;
        } else {
            let reg = temp_load_to(
                ctx,
                state,
                backend,
                buf,
                tidx,
                required,
                i_allocated,
                RegSet::EMPTY,
            );
            i_regs[i] = reg;
            i_allocated = i_allocated.set(reg);
        }
    }

    // Fixup: re-read actual registers after all inputs are
    // processed. A later input's allocation may have evicted
    // an earlier input (e.g. fixed RCX constraint).
    i_allocated = RegSet::EMPTY;
    for i in 0..nb_iargs {
        let tidx = op.args[nb_oargs + i];
        let temp = ctx.temp(tidx);
        if temp.val_type == TempVal::Reg {
            let reg = temp.reg.unwrap();
            i_regs[i] = reg;
            i_allocated = i_allocated.set(reg);
        }
    }

    // 2. Free dead inputs
    for i in 0..nb_iargs {
        if life.is_dead((nb_oargs + i) as u32) {
            let tidx = op.args[nb_oargs + i];
            temp_dead(ctx, state, tidx);
        }
    }

    // 3. Process outputs
    let mut o_regs = [0u8; 10];
    let mut o_allocated = RegSet::EMPTY;
    for k in 0..nb_oargs {
        let arg_ct = &ct.args[k];
        let dst_tidx = op.args[k];

        let reg = if arg_ct.oalias {
            let ai = arg_ct.alias_index as usize;
            if i_reusable[ai] {
                // Reuse the dead input's register
                i_regs[ai]
            } else {
                // Input is still live — copy it away,
                // take its register for the output.
                let old_reg = i_regs[ai];
                let src_tidx = op.args[nb_oargs + ai];
                let src_temp = ctx.temp(src_tidx);
                let ty = src_temp.ty;
                let copy_reg = reg_alloc(
                    ctx,
                    state,
                    backend,
                    buf,
                    state.allocatable,
                    i_allocated.union(o_allocated),
                    RegSet::EMPTY,
                );
                backend.tcg_out_mov(buf, ty, copy_reg, old_reg);
                state.assign(copy_reg, src_tidx);
                let t = ctx.temp_mut(src_tidx);
                t.reg = Some(copy_reg);
                old_reg
            }
        } else if arg_ct.newreg {
            reg_alloc(
                ctx,
                state,
                backend,
                buf,
                arg_ct.regs,
                i_allocated.union(o_allocated),
                RegSet::EMPTY,
            )
        } else {
            reg_alloc(
                ctx,
                state,
                backend,
                buf,
                arg_ct.regs,
                o_allocated,
                RegSet::EMPTY,
            )
        };

        state.assign(reg, dst_tidx);
        let t = ctx.temp_mut(dst_tidx);
        t.val_type = TempVal::Reg;
        t.reg = Some(reg);
        t.mem_coherent = false;
        o_regs[k] = reg;
        o_allocated = o_allocated.set(reg);
    }

    // 4. Collect constant args
    let cstart = nb_oargs + nb_iargs;
    let cargs: Vec<u32> =
        (0..nb_cargs).map(|i| op.args[cstart + i].0).collect();

    // 5. Emit host code
    backend.tcg_out_op(
        buf,
        ctx,
        op,
        &o_regs[..nb_oargs],
        &i_regs[..nb_iargs],
        &cargs,
    );

    // 6. Free dead outputs
    for k in 0..nb_oargs {
        if life.is_dead(k as u32) {
            let tidx = op.args[k];
            temp_dead(ctx, state, tidx);
        }
    }

    // 7. Sync globals if needed
    for i in 0..nb_iargs {
        let arg_pos = (nb_oargs + i) as u32;
        if life.is_sync(arg_pos) {
            let tidx = op.args[nb_oargs + i];
            temp_sync(ctx, backend, buf, tidx);
            ctx.temp_mut(tidx).mem_coherent = true;
        }
    }
}

/// Main register allocation + code generation pass.
pub fn regalloc_and_codegen(
    ctx: &mut Context,
    backend: &impl HostCodeGen,
    buf: &mut CodeBuffer,
) {
    let allocatable = crate::x86_64::regs::ALLOCATABLE_REGS;
    let mut state = RegAllocState::new(allocatable);

    // Initialize fixed temps (always in their register)
    let nb_globals = ctx.nb_globals();
    for i in 0..nb_globals {
        let tidx = TempIdx(i);
        let temp = ctx.temp(tidx);
        if temp.kind == TempKind::Fixed {
            if let Some(reg) = temp.reg {
                state.assign(reg, tidx);
            }
        }
    }

    let num_ops = ctx.num_ops();
    for oi in 0..num_ops {
        let op = ctx.ops()[oi].clone();
        let def = &OPCODE_DEFS[op.opc as usize];
        let flags = def.flags;

        match op.opc {
            Opcode::Nop | Opcode::InsnStart => continue,

            Opcode::Mov => {
                let dst_idx = op.args[0];
                let src_idx = op.args[1];
                let life = op.life;
                let src_reg = temp_load_to(
                    ctx,
                    &mut state,
                    backend,
                    buf,
                    src_idx,
                    allocatable,
                    RegSet::EMPTY,
                    RegSet::EMPTY,
                );
                if life.is_dead(1) {
                    temp_dead(ctx, &mut state, src_idx);
                }
                let dst_reg = reg_alloc(
                    ctx,
                    &mut state,
                    backend,
                    buf,
                    allocatable,
                    RegSet::EMPTY,
                    RegSet::EMPTY,
                );
                state.assign(dst_reg, dst_idx);
                let t = ctx.temp_mut(dst_idx);
                t.val_type = TempVal::Reg;
                t.reg = Some(dst_reg);
                t.mem_coherent = false;
                if dst_reg != src_reg {
                    backend.tcg_out_mov(buf, op.op_type, dst_reg, src_reg);
                }
                if life.is_dead(0) {
                    temp_dead(ctx, &mut state, dst_idx);
                }
            }

            Opcode::SetLabel => {
                let label_id = op.args[0].0;
                sync_globals(ctx, backend, buf);
                let offset = buf.offset();
                let label = ctx.label_mut(label_id);
                label.set_value(offset);
                let uses: Vec<_> = label.uses.drain(..).collect();
                for u in uses {
                    match u.kind {
                        RelocKind::Rel32 => {
                            let disp = (offset as i64) - (u.offset as i64 + 4);
                            buf.patch_u32(u.offset, disp as u32);
                        }
                    }
                }
            }

            Opcode::Br => {
                let label_id = op.args[0].0;
                sync_globals(ctx, backend, buf);
                let label = ctx.label(label_id);
                if label.has_value {
                    crate::x86_64::emitter::emit_jmp(buf, label.value);
                } else {
                    buf.emit_u8(0xE9);
                    let patch_off = buf.offset();
                    buf.emit_u32(0);
                    ctx.label_mut(label_id)
                        .add_use(patch_off, RelocKind::Rel32);
                }
            }

            Opcode::ExitTb | Opcode::GotoTb => {
                sync_globals(ctx, backend, buf);
                let nb_cargs = def.nb_cargs as usize;
                let cstart = (def.nb_oargs + def.nb_iargs) as usize;
                let cargs: Vec<u32> =
                    (0..nb_cargs).map(|i| op.args[cstart + i].0).collect();
                backend.tcg_out_op(buf, ctx, &op, &[], &[], &cargs);
            }

            Opcode::GotoPtr => {
                // Load input register, sync globals,
                // then emit indirect jump.
                let ct = backend.op_constraint(op.opc);
                let tidx = op.args[0];
                let arg_ct = &ct.args[0];
                let reg = temp_load_to(
                    ctx,
                    &mut state,
                    backend,
                    buf,
                    tidx,
                    arg_ct.regs,
                    RegSet::EMPTY,
                    RegSet::EMPTY,
                );
                let life = op.life;
                if life.is_dead(0) {
                    temp_dead(ctx, &mut state, tidx);
                }
                sync_globals(ctx, backend, buf);
                backend.tcg_out_op(buf, ctx, &op, &[], &[reg], &[]);
            }

            Opcode::Mb => {
                // NP (NOT_PRESENT): no register allocation,
                // emit directly.
                crate::x86_64::emitter::emit_mfence(buf);
            }

            Opcode::BrCond => {
                let ct = backend.op_constraint(op.opc);
                let nb_iargs = def.nb_iargs as usize;
                let nb_oargs = def.nb_oargs as usize;
                let nb_cargs = def.nb_cargs as usize;
                let life = op.life;

                let mut iregs = Vec::new();
                let mut i_allocated = RegSet::EMPTY;
                for i in 0..nb_iargs {
                    let tidx = op.args[nb_oargs + i];
                    let arg_ct = &ct.args[nb_oargs + i];
                    let reg = temp_load_to(
                        ctx,
                        &mut state,
                        backend,
                        buf,
                        tidx,
                        arg_ct.regs,
                        i_allocated,
                        RegSet::EMPTY,
                    );
                    iregs.push(reg);
                    i_allocated = i_allocated.set(reg);
                }

                let cstart = nb_oargs + nb_iargs;
                let cargs: Vec<u32> =
                    (0..nb_cargs).map(|i| op.args[cstart + i].0).collect();

                for i in 0..nb_iargs {
                    let arg_pos = (nb_oargs + i) as u32;
                    if life.is_dead(arg_pos) {
                        let tidx = op.args[nb_oargs + i];
                        temp_dead(ctx, &mut state, tidx);
                    }
                }

                sync_globals(ctx, backend, buf);

                let label_id = cargs[1];
                let label = ctx.label(label_id);
                let label_resolved = label.has_value;

                backend.tcg_out_op(buf, ctx, &op, &[], &iregs, &cargs);

                if !label_resolved {
                    let patch_off = buf.offset() - 4;
                    ctx.label_mut(label_id)
                        .add_use(patch_off, RelocKind::Rel32);
                }
            }

            _ => {
                let ct = backend.op_constraint(op.opc);
                regalloc_op(ctx, &mut state, backend, buf, &op, ct);
                if flags.contains(OpFlags::BB_END) {
                    sync_globals(ctx, backend, buf);
                }
            }
        }
    }
}
